{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8e1b4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "174b922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/cleaned_adult-all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68431797",
   "metadata": {},
   "outputs": [],
   "source": [
    "#analysis of the target column\n",
    "df['gross_income'] = df['gross_income'].map({'>50K':1,'<=50K':0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8257c459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "gross_income",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "6286d750-d35f-478a-8b2f-d7611747694c",
       "rows": [
        [
         "0",
         "37109"
        ],
        [
         "1",
         "11681"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "gross_income\n",
       "0    37109\n",
       "1    11681\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gross income (target) column\n",
    "df['gross_income'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4781ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['gross_income'] #target column\n",
    "x = df.drop(columns=['gross_income','fnlwgt','education_num']) #prepare the training dataset - dropping irrelevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2a92b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,KFold,cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler,PolynomialFeatures,OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from category_encoders import TargetEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee450226",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the metrics\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score,accuracy_score\n",
    "def metrics(y_pred,y_test):\n",
    "    PrecisionScore = precision_score(y_pred,y_test)\n",
    "    RecallScore = recall_score(y_pred,y_test)\n",
    "    F1Score = f1_score(y_pred,y_test)\n",
    "    AccuracyScore = accuracy_score(y_pred,y_test)\n",
    "    return PrecisionScore,RecallScore,F1Score,AccuracyScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b10dc563",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(\n",
    "    x,y,test_size=0.2,random_state=42 # split the dataset into four different sets\n",
    ")\n",
    "x_train.to_parquet('data/x_train.parquet',index=False)\n",
    "x_test.to_parquet('data/x_test.parquet',index=False)\n",
    "y_train.to_frame('y_train').to_parquet('data/y_train.parquet',index=False)\n",
    "y_test.to_frame('y_test').to_parquet('data/y_test.parquet',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e1ca12",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = x_train.select_dtypes(include='number').columns.tolist() #isolate numeric columns \n",
    "# we further divide the categorical columns into high cardinality and low cardinality columns\n",
    "high_card_cols = ['education','occupation','workclass','native_country','marital_status']\n",
    "low_card_cols = ['sex','relationship','race'] \n",
    "\n",
    "# numerical data pipeline - scaling numerical values, and introducing polynomial features\n",
    "num_pipe = Pipeline(steps=[\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('poly',PolynomialFeatures(include_bias=False)),\n",
    "])\n",
    "# high cardinality pipeline - use simpleImputer function to impute missing values, replacing missing values with the most frequent\n",
    "# occurence of a value\n",
    "# and the values are target encoded\n",
    "high_card_pipe = Pipeline(steps=[\n",
    "    ('impute',SimpleImputer(strategy='most_frequent')),\n",
    "    ('target',TargetEncoder()),\n",
    "])\n",
    "#low cardinality pipeline - onehot encode values\n",
    "low_card_pipe = Pipeline(steps=[\n",
    "    ('onehot',OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "# project the changes we have made to respective columns using ColumnTransformer \n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num',num_pipe,numeric_cols),\n",
    "    ('low_card',low_card_pipe,low_card_cols),\n",
    "    ('high_card',high_card_pipe,high_card_cols),\n",
    "])\n",
    "\n",
    "# a dictionary of several models and their respective parameters\n",
    "model_and_grid_params = {\n",
    "    #Logistic Regression\n",
    "        'Logistic Regression' : {\n",
    "        'model': LogisticRegression(penalty='l2',solver='lbfgs',n_jobs=-1,verbose=2),\n",
    "        'params' : {\n",
    "            \"preprocessor__num__poly__degree\" : [1,2],\n",
    "            \"classifier__C\": [0.1,1.0,10.0],\n",
    "            \"classifier__max_iter\" : [1000,2000,3000]\n",
    "        }\n",
    "    },\n",
    "    #Decision Trees\n",
    "    'Decision Trees' : {\n",
    "        'model' : DecisionTreeClassifier(),\n",
    "        'params': {\n",
    "            \"preprocessor__num__poly__degree\" : [1,2],\n",
    "            'classifier__max_depth' : [5,10,None],\n",
    "            'classifier__min_samples_split' : [100,150,200]\n",
    "        }\n",
    "    },\n",
    "    #Random Forest classifier\n",
    "    'Random Forest Classifier' : {\n",
    "        'model' : RandomForestClassifier(),\n",
    "        'params' : {\n",
    "            \"preprocessor__num__poly__degree\" : [1,2],\n",
    "            'classifier__n_estimators' : [80,100,120],\n",
    "            'classifier__max_depth' : [5,10,None],\n",
    "            'classifier__min_samples_split' : [100,150,200]\n",
    "        }\n",
    "    },\n",
    "    #XGB Classifier\n",
    "    'XGB Classifier' : {\n",
    "        'model' : XGBClassifier(objective='binary:logistic',verbosity=1,random_state=42),\n",
    "        'params' : {\n",
    "            \"preprocessor__num__poly__degree\" : [1,2],\n",
    "            'classifier__n_estimators' : [80,100,120],\n",
    "            'classifier__learning_rate' : [0.1,0.5,1.0],\n",
    "            'classifier__max_depth' : [3,5,8],\n",
    "            'classifier__reg_lambda' : [0.1,0.5,1,10]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "#cross validation - splitting training data into 5 folds\n",
    "cv = KFold(n_splits=5,shuffle=True,random_state=42)\n",
    "\n",
    "results = {}\n",
    "for name,model_grid in model_and_grid_params.items():\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('preprocessor',preprocessor),\n",
    "        ('classifier',model_grid['model'])\n",
    "    ])\n",
    "\n",
    "    model = GridSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_grid=model_grid['params'],\n",
    "        cv = cv,\n",
    "        refit= True,\n",
    "        scoring='f1_macro',\n",
    "        n_jobs=-1,\n",
    "        verbose=2,\n",
    "        return_train_score=True\n",
    "    )\n",
    "\n",
    "    #Training\n",
    "    model.fit(x_train,y_train)\n",
    "\n",
    "    #Prediction\n",
    "    y_pred = model.predict(x_test)\n",
    "    # y_pred = (y_pred_proba >= 0.5).astype(int) # set decision threshold to 0.5\n",
    "    \n",
    "    PrecisionScore,RecallScore,F1Score,AccuracyScore = metrics(y_pred,y_test)\n",
    "\n",
    "    # store results in a dictionary\n",
    "    results[name] = {\n",
    "        'Best score' : model.best_score_,\n",
    "        'Best params' : model.best_params_,\n",
    "        'Best model' : model.best_estimator_,\n",
    "        'Precision_score' : PrecisionScore,\n",
    "        'recall_score' : RecallScore,\n",
    "        'f1_score' : F1Score,\n",
    "        'accuracy_score' : AccuracyScore\n",
    "    }\n",
    "print('\\n')\n",
    "print('*'*50)\n",
    "print('\\n')\n",
    "\n",
    "# display results\n",
    "for name,result in results.items():\n",
    "    print(f'Model Name : {name}')\n",
    "    print('Best CV score : ',result['Best score'])\n",
    "    print('Best Params : ',result['Best params'])\n",
    "    print('Precision Score',result['Precision_score'])\n",
    "    print('Recall Score: ',result['recall_score'])\n",
    "    print('f1_score : ',result['f1_score'])\n",
    "    print('Accuracy Score : ',result['accuracy_score'])\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d459cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Selected :  XGB Classifier\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/best_model.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pick best model\n",
    "import joblib\n",
    "best_model = max(results.items(), key=lambda kv: kv[1]['Best score'])\n",
    "print('Best Model Selected : ',best_model[0])\n",
    "\n",
    "joblib.dump(best_model,'models/best_model.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
